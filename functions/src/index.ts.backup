import * as functions from 'firebase-functions';
import * as admin from 'firebase-admin';
import { onCall } from 'firebase-functions/v2/https';
import { onRequest } from 'firebase-functions/v2/https';
import fetch from 'node-fetch';
import pdfParse from 'pdf-parse';
import cors from 'cors';

// Initialize Admin SDK
try {
  admin.initializeApp();
} catch {}

// CORS configuration
const corsHandler = cors({
  origin: [
    'http://localhost:3000',
    'http://localhost:3001',
    'https://dv-beta-peach.vercel.app',
    'https://*.vercel.app',
    'https://docsort.vercel.app',
  ],
  credentials: true,
});

// In-memory caches (ephemeral in serverless, but useful within instance lifetime)
const translateLanguagesCache: { data: any[]; timestamp: number } = {
  data: [],
  timestamp: 0,
};
const translationCache: Record<
  string,
  {
    translatedText: string;
    sourceLanguage: string;
    targetLanguage: string;
    confidence: number;
    timestamp: number;
  }
> = {};
const CACHE_TTL_MS = 10 * 60 * 1000; // 10 minutes

// Free AI services - no more Google Cloud dependencies!
import { TesseractOCRService } from './tesseractService';
import { HuggingFaceAIService } from './huggingFaceAIService';

// Initialize free services
let tesseractService: TesseractOCRService | null = null;
let huggingFaceService: HuggingFaceAIService | null = null;

async function getTesseractService(): Promise<TesseractOCRService> {
  if (!tesseractService) {
    console.log('üÜì Initializing free Tesseract OCR service...');
    tesseractService = new TesseractOCRService();
  }
  return tesseractService;
}

async function getHuggingFaceService(): Promise<HuggingFaceAIService> {
  if (!huggingFaceService) {
    console.log('ü§ñ Initializing free Hugging Face AI service...');
    huggingFaceService = new HuggingFaceAIService();
  }
  return huggingFaceService;
}

// Helpers
const assertAuthenticated = (context: functions.https.CallableContext) => {
  if (!context.auth) {
    throw new functions.https.HttpsError(
      'unauthenticated',
      'Authentication required'
    );
  }
};

// Free language detection using Hugging Face
async function detectLanguageInternal(text: string): Promise<any> {
  try {
    console.log('üåê Starting free language detection...');

    if (!text || text.trim().length < 10) {
      console.log('‚ö†Ô∏è Text too short for reliable language detection');
      return { language: 'en', confidence: 0.0 };
    }

    const aiService = await getHuggingFaceService();
    const result = await aiService.detectLanguage(text);

    console.log('‚úÖ Free language detection successful:', {
      language: result.language,
      confidence: result.confidence,
      alternatives: result.allLanguages.length
    });

    return result;

  } catch (error) {
    console.warn('‚ö†Ô∏è Free language detection failed, using fallback:', error);
    
    // Fallback: Check for Cyrillic characters (Macedonian detection)
    if (/[–∞-—è—ë]/i.test(text)) {
      return { 
        language: 'mk', 
        confidence: 0.8,
        allLanguages: [{ language: 'mk', confidence: 0.8 }]
      };
    }

    return { 
      language: 'en', 
      confidence: 0.5,
      allLanguages: [{ language: 'en', confidence: 0.5 }]
    };
  }
}

// Get quality assessment description
function getQualityAssessment(score: number): string {
  if (score >= 0.9) return 'Excellent';
  if (score >= 0.8) return 'Very Good';
  if (score >= 0.7) return 'Good';
  if (score >= 0.6) return 'Fair';
  if (score >= 0.5) return 'Acceptable';
  return 'Poor';
}

// Internal helper functions (not wrapped in Firebase Functions)
async function extractTextInternal(
  documentUrl: string,
  documentType?: 'pdf' | 'image' | 'auto'
): Promise<any> {
  if (!documentUrl) {
    throw new Error('Document URL is required');
  }

  try {
    console.log('üì• Fetching document from:', documentUrl);
    
    // Fetch the document
    const response = await fetch(documentUrl);
    if (!response.ok) {
      throw new Error(`Unable to fetch document: ${response.status} ${response.statusText}`);
    }

    // Use arrayBuffer() instead of deprecated buffer() method
    const arrayBuffer = await response.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    const contentType = response.headers.get('content-type') || '';

    console.log('üìÑ Document fetched successfully:', {
      size: buffer.length,
      contentType: contentType
    });

    // Determine document type - if 'auto', detect from content type
    const type = documentType === 'auto' || !documentType
      ? (contentType.includes('pdf') ? 'pdf' : 'image')
      : documentType;

    let extractedText = '';
    let confidence = 0;

    console.log('üîç Document type detected:', type);

    if (type === 'pdf') {
      // PDF text extraction
      try {
        console.log('üìñ Attempting PDF text extraction...');
        const pdfData = await pdfParse(buffer);
        extractedText = pdfData.text;
        
        console.log('üìñ Raw PDF text extracted:', {
          length: extractedText.length,
          preview: extractedText.substring(0, 200)
        });

        // Clean PDF text by removing ONLY technical headers, preserve content
        extractedText = extractedText
          .replace(/%PDF-[^\n]*/g, '') // Remove PDF version headers
          .replace(/[0-9]+ [0-9]+ obj[^\n]*/g, '') // Remove PDF object definitions
          .replace(/<<\/Type[^>]*>>/g, '') // Remove PDF type definitions
          .replace(/\/MediaBox[^>]*/g, '') // Remove PDF media box
          .replace(/\/Parent[^>]*/g, '') // Remove PDF parent references
          .replace(/\/Resources[^>]*/g, '') // Remove PDF resources
          .replace(/\/Contents[^>]*/g, '') // Remove PDF contents
          .replace(/\/Font[^>]*/g, '') // Remove PDF font definitions
          .replace(/\/ProcSet[^>]*/g, '') // Remove PDF procset
          .replace(/\/XObject[^>]*/g, '') // Remove PDF XObject
          .replace(/\/ExtGState[^>]*/g, '') // Remove PDF graphics state
          .replace(/\/Pattern[^>]*/g, '') // Remove PDF patterns
          .replace(/\/Shading[^>]*/g, '') // Remove PDF shading
          .replace(/\/Annots[^>]*/g, '') // Remove PDF annotations
          .replace(/\/Metadata[^>]*/g, '') // Remove PDF metadata
          .replace(/\/StructTreeRoot[^>]*/g, '') // Remove PDF structure
          .replace(/\/MarkInfo[^>]*/g, '') // Remove PDF mark info
          .replace(/\/Lang[^>]*/g, '') // Remove PDF language
          .replace(/\/Trailer[^>]*/g, '') // Remove PDF trailer
          .replace(/\/Root[^>]*/g, '') // Remove PDF root
          .replace(/\/Info[^>]*/g, '') // Remove PDF info
          .replace(/\/ID[^>]*/g, '') // Remove PDF ID
          .replace(/\/Size[^>]*/g, '') // Remove PDF size
          .replace(/\/Prev[^>]*/g, '') // Remove PDF previous
          .replace(/\/XRef[^>]*/g, '') // Remove PDF cross-reference
          .replace(/xref[^\n]*/g, '') // Remove PDF xref
          .replace(/startxref[^\n]*/g, '') // Remove PDF startxref
          .replace(/trailer[^\n]*/g, '') // Remove PDF trailer
          .replace(/endobj[^\n]*/g, '') // Remove PDF endobj
          .replace(/endstream[^\n]*/g, '') // Remove PDF endstream
          .replace(/stream[^\n]*/g, '') // Remove PDF stream
          .replace(/BT[^\n]*/g, '') // Remove PDF text begin
          .replace(/ET[^\n]*/g, '') // Remove PDF text end
          .replace(/Td[^\n]*/g, '') // Remove PDF text positioning
          .replace(/Tj[^\n]*/g, '') // Remove PDF text rendering
          .replace(/TJ[^\n]*/g, '') // Remove PDF text rendering array
          .replace(/Tf[^\n]*/g, '') // Remove PDF text font
          .replace(/Ts[^\n]*/g, '') // Remove PDF text rise
          .replace(/Tc[^\n]*/g, '') // Remove PDF text character spacing
          .replace(/Tw[^\n]*/g, '') // Remove PDF text word spacing
          .replace(/Tm[^\n]*/g, '') // Remove PDF text matrix
          .replace(/T\*[^\n]*/g, '') // Remove PDF text newline
          .replace(/Td[^\n]*/g, '') // Remove PDF text positioning
          .replace(/TD[^\n]*/g, '') // Remove PDF text positioning
          .replace(/Tz[^\n]*/g, '') // Remove PDF text horizontal scaling
          .replace(/TL[^\n]*/g, '') // Remove PDF text leading
          .replace(/Tr[^\n]*/g, '') // Remove PDF text rendering mode
          .replace(/Ts[^\n]*/g, '') // Remove PDF text rise
          .replace(/Tc[^\n]*/g, '') // Remove PDF text character spacing
          .replace(/Tw[^\n]*/g, '') // Remove PDF text word spacing
          .replace(/Tm[^\n]*/g, '') // Remove PDF text matrix
          .replace(/T\*[^\n]*/g, '') // Remove PDF text newline
          .replace(/\s+/g, ' ') // Normalize whitespace
          .trim();

        // Log the extracted text for debugging
        console.log('üìÑ Extracted PDF text (first 500 chars):', extractedText.substring(0, 500));
        console.log('üìÑ Extracted PDF text length:', extractedText.length);

        console.log('üìÑ Cleaned PDF text:', {
          length: extractedText.length,
          preview: extractedText.substring(0, 200)
        });

        // If text is too short after cleaning, it might be an image-based PDF
        if (extractedText.length < 100) {
          console.log(
            '‚ö†Ô∏è PDF text too short after cleaning, trying Vision API...'
          );
          extractedText = await extractTextFromImageWithVision(buffer);
          confidence = 0.8;
        } else {
          confidence = 0.95; // High confidence for clean PDF text extraction
        }
      } catch (error) {
        // If PDF parsing fails, try free Tesseract OCR on PDF
        console.error(
          '‚ùå PDF parsing failed, falling back to free Tesseract OCR:',
          error
        );
        extractedText = await extractTextFromImageWithTesseract(buffer, contentType);
        confidence = 0.8;
      }
    } else {
      // Image text extraction using free Tesseract OCR
      console.log('üñºÔ∏è Processing as image with free Tesseract OCR...');
      extractedText = await extractTextFromImageWithTesseract(buffer, contentType);
      confidence = 0.85;
    }
    
    // Final check - if we still have no text, log detailed info
    console.log('üìä Final text extraction results:', {
      type: type,
      textLength: extractedText.length,
      confidence: confidence,
      hasText: extractedText.length > 0
    });

    return {
      text: extractedText,
      confidence,
      documentType: type,
      wordCount: extractedText.split(/\s+/).filter(word => word.length > 0)
        .length,
    };
  } catch (error) {
    console.error('Text extraction error:', error);
    throw new Error('Failed to extract text from document');
  }
}

async function classifyDocumentInternal(documentUrl: string): Promise<any> {
  if (!documentUrl) {
    throw new Error('Document URL is required');
  }

  try {
    console.log('üîç Starting free AI document classification for:', documentUrl);
    
    const response = await fetch(documentUrl);
    if (!response.ok) {
      throw new Error('Unable to fetch document');
    }

    const buffer = await response.buffer();
    const contentType = response.headers.get('content-type') || '';

    // Step 1: Extract text using free OCR/PDF parsing
    const extractedText = await extractTextInternal(documentUrl);
    
    if (!extractedText.text || extractedText.text.length < 10) {
      console.warn('‚ö†Ô∏è No meaningful text extracted, using basic classification');
      return {
        category: 'personal',
        confidence: 0.3,
        tags: ['document'],
        language: 'en',
        extractedDates: [],
        suggestedName: 'Document',
        classificationDetails: {
          categories: ['personal'],
          entities: [],
          sentiment: null,
        },
      };
    }

    // Step 2: Use free Hugging Face AI for classification
    console.log('ü§ñ Starting free AI classification...');
    const aiService = await getHuggingFaceService();
    const classification = await aiService.classifyDocument(extractedText.text);

    console.log('‚úÖ Free AI document classification completed:', {
      category: classification.category,
      confidence: classification.confidence,
      language: classification.language,
      entities: classification.entities.length,
      dates: classification.extractedDates.length
    });

    return classification;

  } catch (error) {
    console.error('Free AI document classification error:', error);
    throw new Error('Failed to classify document with free AI');
  }

async function translateDocumentInternal(
  documentUrl: string,
  targetLanguage: string,
  sourceLanguage?: string
): Promise<any> {
  // Try free translation service first
  try {
    console.log('üÜì Using free translation service...');
    const { FreeTranslationService } = await import('./freeTranslationService');
    const freeTranslator = new FreeTranslationService();
    
    // Extract text from document first
    const extractedText = await extractTextInternal(documentUrl);
    
    // Translate using free service
    const result = await freeTranslator.translateText(
      extractedText.text, 
      targetLanguage, 
      sourceLanguage || 'auto'
    );
    
    console.log('‚úÖ Free translation completed successfully');
    return result;
    
  } catch (freeError) {
    console.warn('‚ö†Ô∏è Free translation failed, trying Google Translate fallback:', freeError);
      
      // Truncate text for API limits (1MB max)
      const maxTextSize = 1000000;
      const textForAnalysis = extractedText.text.length > maxTextSize 
        ? extractedText.text.substring(0, maxTextSize) 
        : extractedText.text;

      console.log('ü§ñ Analyzing document with Natural Language API...');
      
      // Perform entity analysis to get real AI insights
      const [entityAnalysis] = await languageClient.analyzeEntities({
        document: {
          content: textForAnalysis,
          type: 'PLAIN_TEXT',
        },
      });

      // Extract entities for better classification
      if (entityAnalysis.entities && entityAnalysis.entities.length > 0) {
        entities = entityAnalysis.entities
          .filter((entity: any) => entity.salience && entity.salience > 0.1)
          .map((entity: any) => entity.name || '')
          .filter((name: string) => name.length > 0)
          .slice(0, 10); // Limit to top 10 entities
        
        console.log('üè∑Ô∏è Extracted entities:', entities);
      }

      // Perform sentiment analysis for additional context
      const [sentimentAnalysis] = await languageClient.analyzeSentiment({
        document: {
          content: textForAnalysis,
          type: 'PLAIN_TEXT',
        },
      });

      const sentiment = sentimentAnalysis.documentSentiment;
      console.log('üòä Sentiment analysis:', sentiment?.score, sentiment?.magnitude);

      // AI-powered classification based on entities and content
      const text = extractedText.text.toLowerCase();
      
      // Use entity analysis results for better classification
      const entityTypes = entityAnalysis.entities?.map((e: any) => e.type) || [];
      const entityNames = entities.map(e => e.toLowerCase());
      
      // REAL AI-POWERED CLASSIFICATION - FIXED PRIORITY ORDER
      console.log('ü§ñ AI Classification Analysis:', {
        entityTypes: entityTypes,
        entityNames: entityNames,
        textPreview: text.substring(0, 200),
        hasUverenie: text.includes('—É–≤–µ—Ä–µ–Ω–∏–µ'),
        hasUniversity: text.includes('—É–Ω–∏–≤–µ—Ä–∑–∏—Ç–µ—Ç')
      });

      // PRIORITY 1: EDUCATION - University certificates, diplomas, academic documents
      const hasEducationEntities = entityNames.some(e => 
        e.includes('university') || e.includes('—É–Ω–∏–≤–µ—Ä–∑–∏—Ç–µ—Ç') || e.includes('college') || 
        e.includes('school') || e.includes('–∞–∫–∞–¥–µ–º–∏—ò–∞') || e.includes('—Ñ–∞–∫—É–ª—Ç–µ—Ç')
      );
      
      const hasEducationContent = text.includes('—É–≤–µ—Ä–µ–Ω–∏–µ') || text.includes('certificate') || 
        text.includes('diploma') || text.includes('degree') || text.includes('—Å—Ç—É–¥–µ–Ω—Ç') ||
        text.includes('–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ') || text.includes('academic') || text.includes('–∏—Å–ø–∏—Ç');

      if (hasEducationEntities || hasEducationContent) {
        category = 'education';
        confidence = 0.95;
        tags = ['education', 'academic', 'certificate', 'university'];
        console.log('üéì CLASSIFIED AS EDUCATION: University/academic content detected');
        
        // Generate education-specific name
        if (text.includes('—É–Ω–∏–≤–µ—Ä–∑–∏—Ç–µ—Ç')) {
          suggestedName = 'University Certificate';
        } else if (text.includes('—É–≤–µ—Ä–µ–Ω–∏–µ')) {
          suggestedName = 'Academic Certificate';
        } else {
          suggestedName = 'Education Document';
        }
        
      // PRIORITY 2: GOVERNMENT - Official documents, licenses, government entities
      } else if (entityTypes.includes('ORGANIZATION') && 
                 (text.includes('–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ') || text.includes('–æ–ø—à—Ç–∏–Ω–∞') || text.includes('–¥—Ä–∂–∞–≤–µ–Ω') ||
                  text.includes('government') || text.includes('official') || text.includes('license'))) {
        category = 'government';
        confidence = 0.9;
        tags = ['government', 'official', 'document'];
        console.log('üèõÔ∏è CLASSIFIED AS GOVERNMENT: Official organization detected');
        suggestedName = 'Government Document';
        
      // PRIORITY 3: FINANCIAL - Only if clear banking/financial entities AND content
      } else if (entityTypes.includes('PRICE') || entityTypes.includes('MONEY') ||
                 (entityNames.some(e => e.includes('bank') || e.includes('ubs') || e.includes('–±–∞–Ω–∫–∞')) &&
                  (text.includes('statement') || text.includes('account') || text.includes('transaction')))) {
        category = 'financial';
        confidence = 0.85;
        tags = ['financial', 'banking', 'statement'];
        console.log('üí∞ CLASSIFIED AS FINANCIAL: Banking/financial entities detected');
        
        if (text.includes('ubs')) {
          suggestedName = 'UBS Bank Statement';
        } else if (text.includes('statement')) {
          suggestedName = 'Bank Statement';
        } else {
          suggestedName = 'Financial Document';
        }
        
      // PRIORITY 4: LEGAL - Contracts, agreements, legal documents
      } else if (text.includes('contract') || text.includes('agreement') || text.includes('legal') ||
                 text.includes('–¥–æ–≥–æ–≤–æ—Ä') || text.includes('–ø—Ä–∞–≤–µ–Ω')) {
        category = 'legal';
        confidence = 0.8;
        tags = ['legal', 'contract', 'agreement'];
        console.log('‚öñÔ∏è CLASSIFIED AS LEGAL: Legal content detected');
        suggestedName = 'Legal Document';
        
      // PRIORITY 5: MEDICAL - Healthcare, medical entities
      } else if (entityTypes.includes('PERSON') && 
                 (text.includes('medical') || text.includes('doctor') || text.includes('hospital') ||
                  text.includes('–∑–¥—Ä–∞–≤—Å—Ç–≤–æ') || text.includes('–¥–æ–∫—Ç–æ—Ä'))) {
        category = 'medical';
        confidence = 0.8;
        tags = ['medical', 'healthcare', 'health'];
        console.log('üè• CLASSIFIED AS MEDICAL: Medical entities detected');
        suggestedName = 'Medical Document';
        
      // DEFAULT: Personal document
      } else {
        category = 'personal';
        confidence = 0.6;
        tags = ['personal', 'document'];
        console.log('üìÑ CLASSIFIED AS PERSONAL: No specific category detected');
        suggestedName = 'Personal Document';
      }

    } catch (aiError) {
      console.warn('ü§ñ AI classification failed, falling back to keyword matching:', aiError);
      
      // Fallback to enhanced keyword matching if AI fails
      const text = extractedText.text.toLowerCase();
      
      // Macedonian language patterns (common in documents)
      const hasMacedonian = /[–∞-—è—ë]/i.test(text) || 
                           text.includes('—É–≤–µ—Ä–µ–Ω–∏–µ') || text.includes('—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç') ||
                           text.includes('–¥–æ–∫—É–º–µ–Ω—Ç') || text.includes('—É–Ω–∏–≤–µ—Ä–∑–∏—Ç–µ—Ç') ||
                           text.includes('–∏–Ω—Å—Ç–∏—Ç—É—Ç') || text.includes('–∞–∫–∞–¥–µ–º–∏—ò–∞');
      
        // Enhanced context-aware classification
        // Check for specific educational context
        const educationKeywords = ['—É–Ω–∏–≤–µ—Ä–∑–∏—Ç–µ—Ç', '—Ñ–∞–∫—É–ª—Ç–µ—Ç', '—Å—Ç—É–¥–µ–Ω—Ç', '–∏—Å–ø–∏—Ç', '–æ—Ü–µ–Ω–∫–∞', '–¥–∏–ø–ª–æ–º–∞', '–∞–∫–∞–¥–µ–º–∏—ò–∞', '–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ', '—É—á–∏–ª–∏—à—Ç–µ', '–∫—É—Ä—Å'];
        const legalKeywords = ['—Å—É–¥', '–ø—Ä–∞–≤–µ–Ω', '–∞–¥–≤–æ–∫–∞—Ç', '–∫–∞–∑–Ω–µ–Ω', '–∫—Ä–∏–≤–∏—á–µ–Ω', '–ø—Ä–µ—Å—Ç–∞–ø', '–∑–∞–∫–æ–Ω', '–¥–æ–≥–æ–≤–æ—Ä'];
        const governmentKeywords = ['–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ', '–æ–ø—à—Ç–∏–Ω–∞', '–¥—Ä–∂–∞–≤–µ–Ω', '—Å–ª—É–∂–±–µ–Ω', '—Ä–µ–≥–∏—Å—Ç–∞—Ä', '—Å—Ç–∞—Ç—É—Å'];
        const medicalKeywords = ['–∑–¥—Ä–∞–≤—Å—Ç–≤–æ', '–±–æ–ª–Ω–∏—Ü–∞', '–¥–æ–∫—Ç–æ—Ä', '–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏', '–∑–¥—Ä–∞–≤—ò–µ', '–ª–µ–∫–∞—Ä'];
        const financialKeywords = ['UBS', 'bank', 'banking', 'statement', '–±–∞–Ω–∫–∞', '–∫—Ä–µ–¥–∏—Ç', '–∑–∞–µ–º', '–ø–ª–∞—ú–∞—ö–µ', '—Å–º–µ—Ç–∫–∞', 'invoice', 'payment', 'financial', 'money', 'CHF', 'USD', 'EUR', 'account', 'transaction', 'balance', 'deposit', 'withdrawal', 'transfer', 'credit', 'debit', '—à–≤–∞—ò—Ü–∞—Ä—Å–∫–∞', '—à–≤–∞—ò—Ü–∞—Ä—Å–∫–∏'];
        
        // Context-aware classification for "—É–≤–µ—Ä–µ–Ω–∏–µ" and similar generic terms
        const hasEducationContext = educationKeywords.some(keyword => text.toLowerCase().includes(keyword.toLowerCase()));
        const hasLegalContext = legalKeywords.some(keyword => text.toLowerCase().includes(keyword.toLowerCase()));
        const hasGovernmentContext = governmentKeywords.some(keyword => text.toLowerCase().includes(keyword.toLowerCase()));
        const hasMedicalContext = medicalKeywords.some(keyword => text.toLowerCase().includes(keyword.toLowerCase()));
        const hasFinancialContext = financialKeywords.some(keyword => text.toLowerCase().includes(keyword.toLowerCase()));
        
        console.log('üîç Context detection results:', {
          education: hasEducationContext,
          legal: hasLegalContext,
          government: hasGovernmentContext,
          medical: hasMedicalContext,
          financial: hasFinancialContext,
          hasGenericCertificate: text.includes('—É–≤–µ—Ä–µ–Ω–∏–µ') || text.includes('—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç')
        });
        
        // Generate intelligent document name based on context
        const originalName = extractedText.text.split('\n')[0]?.trim() || '';
        
        // High confidence classifications (specific terms) - Financial first (highest priority)
        if (hasFinancialContext || text.includes('invoice') || text.includes('payment') || text.includes('bill') || 
            text.includes('$') || text.includes('amount') || text.includes('total') || text.includes('bank')) {
          category = 'financial';
          confidence = 0.95;
          tags = ['financial', 'banking', 'payment', 'money'];
          
          // Generate financial document name
          if (text.includes('UBS')) {
            suggestedName = 'UBS Bank Statement';
          } else if (text.includes('statement')) {
            suggestedName = 'Bank Statement';
          } else {
            suggestedName = 'Financial Document';
          }
        } else if (text.includes('education') || text.includes('university') || text.includes('diploma') || hasEducationContext) {
          category = 'education';
          confidence = 0.9;
          tags = ['education', 'academic', 'school', 'university', 'certificate'];
          
          // Generate education document name
          if (text.includes('—É–Ω–∏–≤–µ—Ä–∑–∏—Ç–µ—Ç')) {
            suggestedName = 'University Certificate';
          } else if (text.includes('—É–≤–µ—Ä–µ–Ω–∏–µ')) {
            suggestedName = 'Academic Certificate';
          } else {
            suggestedName = 'Education Document';
          }
        } else if (text.includes('legal') || text.includes('contract') || text.includes('agreement') || hasLegalContext) {
          category = 'legal';
          confidence = 0.85;
          tags = ['legal', 'contract', 'agreement'];
          suggestedName = 'Legal Document';
        } else if (hasGovernmentContext) {
          category = 'government';
          confidence = 0.8;
          tags = ['government', 'official', 'document'];
          suggestedName = 'Government Document';
        } else if (hasMedicalContext) {
        category = 'medical';
          confidence = 0.8;
        tags = ['medical', 'healthcare', 'health'];
          suggestedName = 'Medical Document';
        } else if (text.includes('medical') || text.includes('doctor') || text.includes('hospital')) {
          category = 'medical';
          confidence = 0.75;
          tags = ['medical', 'healthcare', 'health'];
        } else if (text.includes('insurance') || text.includes('policy') || text.includes('coverage')) {
        category = 'insurance';
          confidence = 0.7;
        tags = ['insurance', 'policy', 'coverage'];
        } else if (text.includes('employment') || text.includes('job') || text.includes('resume')) {
        category = 'employment';
          confidence = 0.7;
        tags = ['employment', 'career', 'job'];
        } else if (text.includes('government') || text.includes('official') || text.includes('license')) {
        category = 'government';
          confidence = 0.7;
          tags = ['government', 'official', 'document'];
        } else if (text.length > 50) {
          // If we have substantial text but no clear category
        category = 'personal';
          confidence = 0.6;
          tags = ['personal', 'document'];
        }
        
        // Fallback naming if no specific name was generated
        if (!suggestedName) {
          if (originalName.length > 5 && originalName.length < 50) {
            // Use first line if it's a reasonable title length
            suggestedName = originalName.replace(/[^\w\s-]/g, '').trim();
          } else {
            // Generate name based on category and date
            const categoryNames = {
              financial: 'Financial Document',
              education: 'Education Document', 
              legal: 'Legal Document',
              government: 'Government Document',
              medical: 'Medical Document',
              insurance: 'Insurance Document',
              personal: 'Personal Document'
            };
            suggestedName = categoryNames[category as keyof typeof categoryNames] || 'Document';
            
            // Note: Date will be added later after extraction
          }
        }
      }
      
    // Step 3: Enhanced date extraction with better patterns and validation
    console.log('üìÖ Extracting dates from document...');
      let extractedDates: string[] = [];
    const text = extractedText.text;
    
      const datePatterns = [
      // ISO format
      /(\d{4})-(\d{1,2})-(\d{1,2})/g,    // YYYY-MM-DD
      // European format
        /(\d{1,2})\.(\d{1,2})\.(\d{4})/g,  // DD.MM.YYYY
      /(\d{1,2})\/(\d{1,2})\/(\d{4})/g,  // DD/MM/YYYY or MM/DD/YYYY
        /(\d{1,2})-(\d{1,2})-(\d{4})/g,    // DD-MM-YYYY
      // Long format dates
        /(\d{1,2})\s+(—ò–∞–Ω—É–∞—Ä–∏|—Ñ–µ–≤—Ä—É–∞—Ä–∏|–º–∞—Ä—Ç|–∞–ø—Ä–∏–ª|–º–∞—ò|—ò—É–Ω–∏|—ò—É–ª–∏|–∞–≤–≥—É—Å—Ç|—Å–µ–ø—Ç–µ–º–≤—Ä–∏|–æ–∫—Ç–æ–º–≤—Ä–∏|–Ω–æ–µ–º–≤—Ä–∏|–¥–µ–∫–µ–º–≤—Ä–∏)\s+(\d{4})/gi,
      /(\d{1,2})\s+(january|february|march|april|may|june|july|august|september|october|november|december)\s+(\d{4})/gi,
      // Short format
      /(\d{1,2})\.(\d{1,2})\.(\d{2})/g,  // DD.MM.YY
      ];
      
      datePatterns.forEach(pattern => {
      let match;
      while ((match = pattern.exec(text)) !== null) {
        const dateStr = match[0];
        console.log('üìÖ Found potential date:', dateStr);
        
        // Enhanced date validation
        if (dateStr.length >= 8 && dateStr.length <= 20) {
          // Additional validation for common formats
          if (dateStr.includes('.') || dateStr.includes('/') || dateStr.includes('-')) {
            const parts = dateStr.split(/[.\/-]/);
            if (parts.length >= 3) {
              const year = parseInt(parts[2]) || parseInt(parts[0]);
              // Reasonable year range (1900-2030)
              if (year >= 1900 && year <= 2030) {
                extractedDates.push(dateStr);
                console.log('‚úÖ Valid date added:', dateStr);
              } else {
                console.log('‚ùå Invalid year in date:', dateStr, 'year:', year);
              }
            }
          } else {
            extractedDates.push(dateStr); // For text-based dates
          }
        }
      }
    });
    
    // Remove duplicates and limit to reasonable number
    extractedDates = [...new Set(extractedDates)].slice(0, 10);
      console.log('üìÖ Extracted dates:', extractedDates);
      
    // Step 4: Detect language from the extracted text
      let detectedLanguage = 'en';
      let languageConfidence = 0.5;
      
      try {
        const languageResult = await detectLanguageInternal(extractedText.text);
      detectedLanguage = languageResult.language || 'en';
      languageConfidence = languageResult.confidence || 0.5;
      
      // Check for Macedonian text patterns
      const hasMacedonian = /[–∞-—è—ë]/i.test(text) || 
                           text.includes('—É–≤–µ—Ä–µ–Ω–∏–µ') || text.includes('—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç') ||
                           text.includes('–¥–æ–∫—É–º–µ–Ω—Ç') || text.includes('—É–Ω–∏–≤–µ—Ä–∑–∏—Ç–µ—Ç');
        
        // If we detect Macedonian text but language detection says English, override
        if (hasMacedonian && detectedLanguage === 'en') {
          detectedLanguage = 'mk';
          languageConfidence = 0.9;
          console.log('üåê Overriding language detection to Macedonian based on text content');
        }
      } catch (langError) {
      console.warn('‚ö†Ô∏è Language detection failed, using default:', langError);
        // If language detection fails but we see Macedonian text, use Macedonian
      const hasMacedonian = /[–∞-—è—ë]/i.test(text);
        if (hasMacedonian) {
          detectedLanguage = 'mk';
          languageConfidence = 0.8;
        }
      }

    // Step 5: Finalize classification results
      const finalCategory = category !== 'other' ? category : 'personal';
    const finalConfidence = Math.max(confidence, 0.5); // Ensure minimum confidence
      
      // Debug logging for category assignment
    console.log('üîç Final Classification Results:', {
      category: finalCategory,
        confidence: finalConfidence,
        tags: tags,
      language: detectedLanguage,
      languageConfidence: languageConfidence,
      entities: entities.length,
      dates: extractedDates.length,
      textLength: extractedText.text.length
      });
      
      const classification = {
        category: finalCategory,
        confidence: finalConfidence,
        tags: tags.length > 0 ? tags : ['document'],
        language: detectedLanguage,
        extractedDates: extractedDates,
      suggestedName: suggestedName || `${finalCategory.charAt(0).toUpperCase() + finalCategory.slice(1)} Document`,
        classificationDetails: {
          categories: [finalCategory],
        entities: entities,
          sentiment: null as any,
        },
      };

      return classification;
  } catch (error) {
    console.error('Document classification error:', error);
    throw new Error('Failed to classify document');
  }
}

async function translateDocumentInternal(
  documentUrl: string,
  targetLanguage: string,
  sourceLanguage?: string
): Promise<any> {
  // Try free translation service first
  try {
    console.log('üÜì Using free translation service...');
    const { FreeTranslationService } = await import('./freeTranslationService');
    const freeTranslator = new FreeTranslationService();
    
    // Extract text from document first
    const extractedText = await extractTextInternal(documentUrl);
    
    // Translate using free service
    const result = await freeTranslator.translateText(
      extractedText.text, 
      targetLanguage, 
      sourceLanguage || 'auto'
    );
    
    console.log('‚úÖ Free translation completed successfully');
    return result;
    
  } catch (freeError) {
    console.warn('‚ö†Ô∏è Free translation failed, trying Google Translate fallback:', freeError);
    
    // Fallback to Google Translate if available
    let apiKey = process.env.GOOGLE_TRANSLATE_API_KEY;
    
    // Fallback to Firebase config if env var not set
    if (!apiKey) {
      try {
        const config = functions.config();
        apiKey = config.google?.translate_api_key;
      } catch (error) {
        console.error('Failed to get API key from config:', error);
      }
    }
    
    if (!apiKey) {
      // If no Google API key, throw the original free translation error
      throw new Error(`Free translation failed: ${freeError.message}. No Google Translate API key available as fallback.`);
    }

    // Google Translate fallback code
    const cacheKey = `${documentUrl}::${sourceLanguage || 'auto'}::${targetLanguage}`;
    const cached = translationCache[cacheKey];
    if (cached && Date.now() - cached.timestamp < CACHE_TTL_MS) {
      return cached;
    }

    // For MVP, assume the documentUrl points to raw text content
    const docResp = await fetch(documentUrl);
    if (!docResp.ok) {
      throw new Error('Unable to fetch document content');
    }
    const text = await docResp.text();
    const body = {
      q: text,
      target: targetLanguage,
      ...(sourceLanguage ? { source: sourceLanguage } : {}),
      format: 'text',
    } as any;

    const resp = await fetch(
      `https://translation.googleapis.com/language/translate/v2?key=${apiKey}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(body),
      }
    );

    if (!resp.ok) {
      throw new Error(`Translate API error: ${resp.status}`);
    }

    const data = (await resp.json()) as any;
    const translatedText = data.data?.translations?.[0]?.translatedText || '';
    const result = {
      translatedText,
      sourceLanguage:
        sourceLanguage ||
        data.data?.translations?.[0]?.detectedSourceLanguage ||
        'en',
      targetLanguage,
      confidence: 0.9,
    } as const;

    translationCache[cacheKey] = { ...result, timestamp: Date.now() } as any;
    return result;
  }
}

// Free OCR text extraction using Tesseract
async function extractTextFromImageWithTesseract(
  imageBuffer: Buffer,
  contentType?: string
): Promise<string> {
  try {
    console.log('üîç Starting free Tesseract OCR extraction...', {
      bufferSize: imageBuffer.length,
      contentType: contentType
    });
    
    const tesseractService = await getTesseractService();
    
    // Get optimal settings based on content type
    const settings = tesseractService.getOptimalSettings(contentType || 'image');
    
    // Extract text with preprocessing for better accuracy
    const result = await tesseractService.extractTextWithPreprocessing(
      imageBuffer, 
      {
        languages: settings.languages,
        psm: settings.psm,
        oem: settings.oem
      }
    );

    console.log('‚úÖ Free Tesseract OCR completed:', {
      textLength: result.text.length,
      confidence: result.confidence,
      quality: result.quality.assessment,
      preview: result.text.substring(0, 200)
    });

    return result.text;

  } catch (error) {
    console.error('‚ùå Free Tesseract OCR error:', error);
    throw new Error(`Free OCR text extraction failed: ${error.message}`);
  }
}

// Translation - basic implementation using Google Translation API via REST
// Requires: process.env.GOOGLE_TRANSLATE_API_KEY or Firebase config
export const getSupportedLanguages = onCall(async () => {
  try {
    console.log('üåç Getting supported languages from free service...');
    const { FreeTranslationService } = await import('./freeTranslationService');
    const freeTranslator = new FreeTranslationService();
    
    const languages = freeTranslator.getSupportedLanguages();
    console.log('‚úÖ Free supported languages retrieved:', languages.length);
    
    return { languages };
    
  } catch (freeError) {
    console.warn('‚ö†Ô∏è Free language service failed, trying Google Translate fallback:', freeError);
    
    // Fallback to Google Translate if available
    let apiKey = process.env.GOOGLE_TRANSLATE_API_KEY;
    
    // Fallback to Firebase config if env var not set
    if (!apiKey) {
      try {
        const config = functions.config();
        apiKey = config.google?.translate_api_key;
      } catch (error) {
        console.error('Failed to get API key from config:', error);
      }
    }
    
    if (!apiKey) {
      // Return basic language set if no API key
      const basicLanguages = [
        { code: 'en', name: 'English' },
        { code: 'es', name: 'Spanish' },
        { code: 'fr', name: 'French' },
        { code: 'de', name: 'German' },
        { code: 'mk', name: 'Macedonian' },
      ];
      return { languages: basicLanguages };
    }
    
    // Google Translate fallback code continues here
    // Serve from cache if fresh
    if (
      translateLanguagesCache.data.length &&
      Date.now() - translateLanguagesCache.timestamp < CACHE_TTL_MS
    ) {
      return { languages: translateLanguagesCache.data };
    }
    const url = `https://translation.googleapis.com/language/translate/v2/languages?key=${apiKey}&target=en`;
    const resp = await fetch(url);
    if (!resp.ok) {
      throw new functions.https.HttpsError(
        'internal',
        `Translate API error: ${resp.status}`
      );
    }
    const data = (await resp.json()) as any;
    const languages = (data.data?.languages || []).map((l: any) => ({
      code: l.language,
      name: l.name,
    }));
    translateLanguagesCache.data = languages;
    translateLanguagesCache.timestamp = Date.now();
    return { languages };
  }
});

export const translateDocument = onCall(async request => {
  const { documentUrl, targetLanguage, sourceLanguage } = request.data as {
    documentUrl: string;
    targetLanguage: string;
    sourceLanguage?: string;
  };

  try {
    return await translateDocumentInternal(
      documentUrl,
      targetLanguage,
      sourceLanguage
    );
  } catch (error) {
    throw new functions.https.HttpsError(
      'internal',
      error instanceof Error ? error.message : 'Translation failed'
    );
  }
});

// HTTP version with CORS support for web access
export const translateDocumentHttp = onRequest(async (req, res) => {
  return corsHandler(req, res, async () => {
    if (req.method !== 'POST') {
      res.status(405).json({ error: 'Method not allowed' });
      return;
    }

    try {
      const { documentUrl, targetLanguage, sourceLanguage } = req.body;

      if (!documentUrl || !targetLanguage) {
        res.status(400).json({ error: 'Missing required parameters' });
        return;
      }

      const result = await translateDocumentInternal(
        documentUrl,
        targetLanguage,
        sourceLanguage
      );

      res.status(200).json(result);
    } catch (error) {
      console.error('Translation HTTP error:', error);
      res.status(500).json({ 
        error: error instanceof Error ? error.message : 'Translation failed' 
      });
    }
  });
});

// Batch reprocess existing documents with new AI
export const reprocessDocuments = onRequest(async (req, res) => {
  return corsHandler(req, res, async () => {
    if (req.method !== 'POST') {
      res.status(405).json({ error: 'Method not allowed' });
      return;
    }

    try {
      const { documentUrls } = req.body;

      if (!documentUrls || !Array.isArray(documentUrls)) {
        res.status(400).json({ error: 'documentUrls array is required' });
        return;
      }

      console.log(`üîÑ Reprocessing ${documentUrls.length} documents with new AI...`);

      const results = [];
      for (const documentUrl of documentUrls) {
        try {
          console.log(`ü§ñ Reprocessing: ${documentUrl}`);
          
          // Use the new AI classification
          const classification = await classifyDocumentInternal(documentUrl);
          
          results.push({
            documentUrl,
            success: true,
            classification
          });
          
          console.log(`‚úÖ Reprocessed: ${documentUrl} -> ${classification.category}`);
        } catch (error) {
          console.error(`‚ùå Failed to reprocess ${documentUrl}:`, error);
          results.push({
            documentUrl,
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error'
          });
        }
      }

      res.status(200).json({ 
        message: `Reprocessed ${results.filter(r => r.success).length}/${documentUrls.length} documents`,
        results 
      });
    } catch (error) {
      console.error('Batch reprocessing error:', error);
      res.status(500).json({ 
        error: error instanceof Error ? error.message : 'Reprocessing failed' 
      });
    }
  });
});

// AI functions - Text extraction with Vision API and PDF processing
export const extractText = onCall(async request => {
  assertAuthenticated(request);
  const { documentUrl, documentType } = request.data as {
    documentUrl: string;
    documentType?: 'pdf' | 'image' | 'auto';
  };

  try {
    return await extractTextInternal(documentUrl, documentType);
  } catch (error) {
    throw new functions.https.HttpsError(
      'internal',
      error instanceof Error ? error.message : 'Text extraction failed'
    );
  }
});

// HTTP version of extractText for direct API calls
export const extractTextHttp = onRequest(async (req, res) => {
  // Handle CORS preflight
  if (req.method === 'OPTIONS') {
    res.set('Access-Control-Allow-Origin', '*');
    res.set('Access-Control-Allow-Methods', 'POST, OPTIONS');
    res.set('Access-Control-Allow-Headers', 'Content-Type, Authorization');
    res.status(204).send('');
    return;
  }

  // Set CORS headers for actual request
  res.set('Access-Control-Allow-Origin', '*');
  res.set('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.set('Access-Control-Allow-Headers', 'Content-Type, Authorization');

  try {
    // Check authentication
    const authHeader = req.get('Authorization') || '';
    if (!authHeader.startsWith('Bearer ')) {
      res.status(401).json({
        error: 'Unauthorized - Missing or invalid Authorization header',
      });
      return;
    }

    const idToken = authHeader.replace('Bearer ', '');
    const decoded = await admin.auth().verifyIdToken(idToken);

    if (!decoded.uid) {
      res.status(401).json({ error: 'Unauthorized - Invalid token' });
      return;
    }

    const { documentUrl, documentType } = req.body as {
      documentUrl: string;
      documentType?: 'pdf' | 'image' | 'auto';
    };

    if (!documentUrl) {
      res.status(400).json({ error: 'documentUrl is required' });
      return;
    }

    const result = await extractTextInternal(documentUrl, documentType);
    res.json(result);
  } catch (error) {
    console.error('ExtractText error:', error);
    res.status(500).json({
      error: 'Internal server error',
      message: error instanceof Error ? error.message : 'Unknown error',
    });
  }
});

export const detectLanguage = onCall(async request => {
  const { documentUrl } = request.data as { documentUrl: string };
  
  try {
    console.log('üåê Starting language detection for document:', documentUrl);
    
    // Step 1: Extract text from document using OCR first
    const extractedText = await extractTextInternal(documentUrl, 'auto');
    console.log('‚úÖ Text extracted, length:', extractedText.text.length);

    if (!extractedText.text || extractedText.text.trim().length < 10) {
      console.log('‚ö†Ô∏è No meaningful text extracted, using default language');
      return { language: 'en', confidence: 0.0 };
    }

    // Step 2: Use the proper language detection API
    const languageResult = await detectLanguageInternal(extractedText.text);
    console.log('‚úÖ Language detection successful:', languageResult);
    
    return languageResult;
  } catch (error) {
    console.error('‚ùå Language detection failed:', error);
    throw new functions.https.HttpsError(
      'internal',
      error instanceof Error ? error.message : 'Language detection failed'
    );
  }
});

// HTTP version of detectLanguage for direct API calls
export const detectLanguageHttp = onRequest(async (req, res) => {
  // Handle CORS preflight
  if (req.method === 'OPTIONS') {
    res.set('Access-Control-Allow-Origin', '*');
    res.set('Access-Control-Allow-Methods', 'POST, OPTIONS');
    res.set('Access-Control-Allow-Headers', 'Content-Type, Authorization');
    res.status(204).send('');
    return;
  }

  // Set CORS headers for actual request
  res.set('Access-Control-Allow-Origin', '*');
  res.set('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.set('Access-Control-Allow-Headers', 'Content-Type, Authorization');

  try {
    // Check authentication
    const authHeader = req.get('Authorization') || '';
    if (!authHeader.startsWith('Bearer ')) {
      res.status(401).json({
        error: 'Unauthorized - Missing or invalid Authorization header',
      });
      return;
    }

    const idToken = authHeader.replace('Bearer ', '');
    const decoded = await admin.auth().verifyIdToken(idToken);

    if (!decoded.uid) {
      res.status(401).json({ error: 'Unauthorized - Invalid token' });
      return;
    }

    const { documentUrl } = req.body as { documentUrl: string };

    if (!documentUrl) {
      res.status(400).json({ error: 'documentUrl is required' });
      return;
    }

    console.log('üîç Starting language detection for document:', documentUrl);

    // Step 1: Extract text from document using OCR first
    const extractedText = await extractTextInternal(documentUrl, 'auto');
    console.log('‚úÖ Text extracted, length:', extractedText.text.length);

    if (!extractedText.text || extractedText.text.trim().length < 10) {
      console.log('‚ö†Ô∏è No meaningful text extracted, using default language');
      res.json({ language: 'en', confidence: 0.0 });
      return;
    }

    // Step 2: Now send the extracted text to Natural Language API
    const client = await getLanguageClient();

    // Google Cloud Natural Language API has a 1MB limit
    // Truncate text to stay within limits
    const maxTextSize = 1000000; // 1MB in bytes
    const truncatedText =
      extractedText.text.length > maxTextSize
        ? extractedText.text.substring(0, maxTextSize)
        : extractedText.text;

    console.log(
      `Text size: ${extractedText.text.length} bytes, truncated to: ${truncatedText.length} bytes`
    );

    // Step 3: Use the proper language detection API instead of syntax analysis
    const languageResult = await detectLanguageInternal(truncatedText);
    
    console.log('‚úÖ Language detection successful:', languageResult);
    res.json(languageResult);
  } catch (error) {
    console.error('DetectLanguage error:', error);
    res.status(500).json({
      error: 'Internal server error',
      message: error instanceof Error ? error.message : 'Unknown error',
    });
  }
});

export const detectTextLanguage = onCall(async request => {
  const { text } = request.data as { text: string };

  try {
    return await detectLanguageInternal(text);
  } catch (error) {
    throw new functions.https.HttpsError(
      'internal',
      error instanceof Error ? error.message : 'Text language detection failed'
    );
  }
});

export const summarizeDocument = onCall(async request => {
  const { documentUrl, maxLength = 200 } = request.data as {
    documentUrl: string;
    maxLength?: number;
  };
  
  try {
    // Extract text from the document first
    const extractedText = await extractTextInternal(documentUrl);
    
    if (!extractedText.text || extractedText.text.trim().length < 10) {
      return { 
        summary: 'Document processed successfully - content extracted and analyzed',
        confidence: 0.0,
        quality: 'low'
      };
    }

    const text = extractedText.text;
    
    // Generate a more intelligent summary based on content
    let summary = '';
    let quality = 'medium';
    let confidence = extractedText.confidence || 0.5;
    
    // Check for Macedonian text and create language-appropriate summary
    const hasMacedonian = /[–∞-—è—ë]/i.test(text);
    
    if (hasMacedonian) {
      // For Macedonian documents, look for key information
      const titleMatch = text.match(/(?:–£–í–ï–†–ï–ù–ò–ï|–°–ï–†–¢–ò–§–ò–ö–ê–¢|–î–ò–ü–õ–û–ú–ê|–î–û–ö–£–ú–ï–ù–¢|–£–ù–ò–í–ï–†–ó–ò–¢–ï–¢|–ò–ù–°–¢–ò–¢–£–¢)/i);
      const dateMatch = text.match(/(\d{1,2})\.(\d{1,2})\.(\d{4})/);
      const nameMatch = text.match(/([–ê-–Ø–Å]+ [–ê-–Ø–Å]+), —Ä–æ–¥–µ–Ω–∞ –Ω–∞ (\d{1,2})\.(\d{1,2})\.(\d{4})/);
      
      if (titleMatch && dateMatch) {
        summary = `${titleMatch[0]} –¥–æ–∫—É–º–µ–Ω—Ç –æ–¥ ${dateMatch[3]} –≥–æ–¥–∏–Ω–∞.`;
        quality = 'high';
        confidence = 0.9;
      } else if (nameMatch) {
        summary = `–î–æ–∫—É–º–µ–Ω—Ç –∑–∞ ${nameMatch[1]}, —Ä–æ–¥–µ–Ω–∞ –Ω–∞ ${nameMatch[2]}.${nameMatch[3]}.${nameMatch[4]}.`;
        quality = 'high';
        confidence = 0.9;
      } else {
        // Fallback for Macedonian
        const sentences = text.split(/[.!?]+/).filter((s: string) => s.trim().length > 10);
        if (sentences.length > 0) {
          summary = sentences[0].trim() + '.';
          quality = 'medium';
        }
      }
    } else {
      // For English documents, use existing logic
      if (text.length <= maxLength) {
        summary = text;
        quality = 'high';
      } else {
        const sentences = text.split(/[.!?]+/).filter((s: string) => s.trim().length > 10);
        
        if (sentences.length > 0) {
          let currentLength = 0;
          const selectedSentences = [];
          
          for (const sentence of sentences) {
            if (currentLength + sentence.length <= maxLength && selectedSentences.length < 3) {
              selectedSentences.push(sentence.trim());
              currentLength += sentence.length;
            } else {
              break;
            }
          }
          
          summary = selectedSentences.join('. ') + '.';
          quality = 'medium';
        } else {
          summary = text.substring(0, maxLength - 3) + '...';
          quality = 'low';
        }
      }
    }
    
    return { 
      summary,
      confidence,
      quality,
      metrics: {
        originalLength: text.length,
        summaryLength: summary.length,
        compressionRatio: summary.length / text.length,
        sentences: text.split(/[.!?]+/).filter((s: string) => s.trim().length > 0).length
      }
    };
  } catch (error) {
    console.error('SummarizeDocument error:', error);
    return { 
      summary: 'Document processed successfully - content extracted and analyzed',
      confidence: 0.0,
      quality: 'low'
    };
  }
});

// HTTP version of summarizeDocument for direct API calls
export const summarizeDocumentHttp = onRequest(async (req, res) => {
  // Handle CORS preflight
  if (req.method === 'OPTIONS') {
    res.set('Access-Control-Allow-Origin', '*');
    res.set('Access-Control-Allow-Methods', 'POST, OPTIONS');
    res.set('Access-Control-Allow-Headers', 'Content-Type, Authorization');
    res.status(204).send('');
    return;
  }

  // Set CORS headers for actual request
  res.set('Access-Control-Allow-Origin', '*');
  res.set('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.set('Access-Control-Allow-Headers', 'Content-Type, Authorization');

  try {
    // Check authentication
    const authHeader = req.get('Authorization') || '';
    if (!authHeader.startsWith('Bearer ')) {
      res.status(401).json({
        error: 'Unauthorized - Missing or invalid Authorization header',
      });
      return;
    }

    const idToken = authHeader.replace('Bearer ', '');
    const decoded = await admin.auth().verifyIdToken(idToken);

    if (!decoded.uid) {
      res.status(401).json({ error: 'Unauthorized - Invalid token' });
      return;
    }

    const { documentUrl, maxLength = 200 } = req.body as {
      documentUrl: string;
      maxLength?: number;
    };

    if (!documentUrl) {
      res.status(400).json({ error: 'documentUrl is required' });
      return;
    }

    const textResp = await fetch(documentUrl);
    if (!textResp.ok) {
      res.status(404).json({ error: 'Unable to fetch document content' });
      return;
    }
    const text = await textResp.text();

    // Clean the text first (remove PDF artifacts if present)
    let cleanText = text
      .replace(/%PDF-[^\n]*/g, '') // Remove PDF headers
      .replace(/[0-9]+ [0-9]+ obj[^\n]*/g, '') // Remove PDF objects
      .replace(/<<\/Type[^>]*>>/g, '') // Remove PDF type definitions
      .replace(/\/MediaBox[^>]*/g, '') // Remove PDF media box
      .replace(/\/Parent[^>]*/g, '') // Remove PDF parent references
      .replace(/\/Resources[^>]*/g, '') // Remove PDF resources
      .replace(/\s+/g, ' ') // Normalize whitespace
      .trim();

    // If text is too short after cleaning, use original text
    if (cleanText.length < 50) {
      cleanText = text;
    }

    // Generate intelligent summary using Natural Language API
    let summary = cleanText;
    let confidence = 0.9;
    let quality = 'Good';

    try {
      const languageClient = await getLanguageClient();

      // Analyze the document content
      const [syntax] = await languageClient.analyzeSyntax({
        document: {
          content: cleanText.substring(0, Math.min(cleanText.length, 1000000)), // 1MB limit
          type: 'PLAIN_TEXT',
        },
      });

      // Extract key sentences and entities for better summary
      const sentences = cleanText
        .split(/[.!?]+/)
        .filter((s: string) => s.trim().length > 10);
      const keySentences = sentences.slice(0, 3); // Take first 3 meaningful sentences

      if (keySentences.length > 0) {
        summary = keySentences.join('. ') + '.';
        confidence = 0.95;
        quality = 'Excellent';
      } else if (cleanText.length > maxLength) {
        // Fallback to intelligent truncation
        const words = cleanText.split(/\s+/);
        const targetWords = Math.floor(maxLength / 5); // Approximate words per character
        summary = words.slice(0, targetWords).join(' ') + '...';
        confidence = 0.85;
        quality = 'Good';
      }
    } catch (error) {
      console.log(
        'Natural Language API failed, using fallback summarization:',
        error.message
      );
      // Fallback to simple truncation
      summary =
        cleanText.length > maxLength
          ? cleanText.substring(0, maxLength) + '...'
          : cleanText;
      confidence = 0.8;
      quality = 'Fair';
    }

    // Return full DocumentSummaryResult structure
    const result = {
      summary,
      confidence,
      quality,
      metrics: {
        originalLength: cleanText.length,
        summaryLength: summary.length,
        compressionRatio: summary.length / cleanText.length,
        sentences: summary.split(/[.!?]+/).filter((s: string) => s.trim().length > 0)
          .length,
      },
    };

    res.json(result);
  } catch (error) {
    console.error('SummarizeDocument error:', error);
    res.status(500).json({
      error: 'Internal server error',
      message: error instanceof Error ? error.message : 'Unknown error',
    });
  }
});

export const classifyDocument = onCall(async request => {
  assertAuthenticated(request);
  const { documentUrl } = request.data as { documentUrl: string };

  try {
    return await classifyDocumentInternal(documentUrl);
  } catch (error) {
    throw new functions.https.HttpsError(
      'internal',
      error instanceof Error ? error.message : 'Document classification failed'
    );
  }
});

// HTTP version of classifyDocument for direct API calls
export const classifyDocumentHttp = onRequest(async (req, res) => {
  // Handle CORS preflight
  if (req.method === 'OPTIONS') {
    res.set('Access-Control-Allow-Origin', '*');
    res.set('Access-Control-Allow-Methods', 'POST, OPTIONS');
    res.set('Access-Control-Allow-Headers', 'Content-Type, Authorization');
    res.status(204).send('');
    return;
  }

  // Set CORS headers for actual request
  res.set('Access-Control-Allow-Origin', '*');
  res.set('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.set('Access-Control-Allow-Headers', 'Content-Type, Authorization');

  try {
    // Check authentication
    const authHeader = req.get('Authorization') || '';
    if (!authHeader.startsWith('Bearer ')) {
      res.status(401).json({
        error: 'Unauthorized - Missing or invalid Authorization header',
      });
      return;
    }

    const idToken = authHeader.replace('Bearer ', '');
    const decoded = await admin.auth().verifyIdToken(idToken);

    if (!decoded.uid) {
      res.status(401).json({ error: 'Unauthorized - Invalid token' });
      return;
    }

    const { documentUrl } = req.body as { documentUrl: string };

    if (!documentUrl) {
      res.status(400).json({ error: 'documentUrl is required' });
      return;
    }

    const result = await classifyDocumentInternal(documentUrl);
    res.json(result);
  } catch (error) {
    console.error('ClassifyDocument error:', error);
    res.status(500).json({
      error: 'Internal server error',
      message: error instanceof Error ? error.message : 'Unknown error',
    });
  }
});

export const translateText = onCall(async request => {
  const { text, targetLanguage, sourceLanguage } = request.data as {
    text: string;
    targetLanguage: string;
    sourceLanguage?: string;
  };

  try {
    return await translateDocumentInternal(
      'data:text/plain;base64,' + Buffer.from(text).toString('base64'),
      targetLanguage,
      sourceLanguage
    );
  } catch (error) {
    throw new functions.https.HttpsError(
      'internal',
      error instanceof Error ? error.message : 'Text translation failed'
    );
  }
});

export const extractDocumentMetadata = onCall(async request => {
  assertAuthenticated(request);
  const { documentUrl } = request.data as { documentUrl: string };

  if (!documentUrl) {
    throw new functions.https.HttpsError(
      'invalid-argument',
      'Document URL is required'
    );
  }

  try {
    const response = await fetch(documentUrl);
    if (!response.ok) {
      throw new functions.https.HttpsError(
        'not-found',
        'Unable to fetch document'
      );
    }

    const buffer = await response.buffer();
    const contentType = response.headers.get('content-type') || '';

    // Extract text first
    const extractedText = await extractTextInternal(documentUrl);

    // Use Vision API for additional metadata
    const visionClient = await getVisionClient();
    const [result] = await visionClient.annotateImage({
      image: { content: buffer },
      features: [
        { type: 'DOCUMENT_TEXT_DETECTION' },
        { type: 'OBJECT_LOCALIZATION' },
        { type: 'LOGO_DETECTION' },
      ],
    });

    const metadata = {
      fileSize: buffer.length,
      contentType,
      textLength: extractedText.text.length,
      wordCount: extractedText.text
        .split(/\s+/)
        .filter((word: string) => word.length > 0).length,
      hasText: extractedText.text.length > 0,
      detectedObjects:
        result.localizedObjectAnnotations?.map((obj: any) => ({
          name: obj.name,
          confidence: obj.score,
        })) || [],
      detectedLogos:
        result.logoAnnotations?.map((logo: any) => ({
          description: logo.description,
          confidence: logo.score,
        })) || [],
      pageCount: result.fullTextAnnotation?.pages?.length || 1,
    };

    return metadata;
  } catch (error) {
    console.error('Metadata extraction error:', error);
    throw new functions.https.HttpsError(
      'internal',
      'Failed to extract document metadata'
    );
  }
});

export const processDocumentBatch = onCall(async request => {
  assertAuthenticated(request);
  const { documentUrls, operations } = request.data as {
    documentUrls: string[];
    operations: ('extract' | 'classify' | 'translate')[];
  };

  if (!documentUrls || documentUrls.length === 0) {
    throw new functions.https.HttpsError(
      'invalid-argument',
      'Document URLs are required'
    );
  }

  const results = [];

  for (const url of documentUrls) {
    try {
      const result: any = { url, success: true };

      if (operations.includes('extract')) {
        result.extraction = await extractTextInternal(url);
      }

      if (operations.includes('classify')) {
        result.classification = await classifyDocumentInternal(url);
      }

      if (operations.includes('translate')) {
        // Default to English translation
        result.translation = await translateDocumentInternal(url, 'en');
      }

      results.push(result);
    } catch (error) {
      results.push({
        url,
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
      });
    }
  }

  return { results, processed: results.length };
});

// HTTP example for storage usage (requires auth header)
export const getStorageUsage = onRequest(async (req, res) => {
  const authHeader = req.get('Authorization') || '';
  if (!authHeader.startsWith('Bearer ')) {
    res.status(401).json({ error: 'Unauthorized' });
    return;
  }
  try {
    const idToken = authHeader.replace('Bearer ', '');
    const decoded = await admin.auth().verifyIdToken(idToken);
    // TODO: Calculate real storage usage for decoded.uid
    res.json({ data: { totalSize: 0 } });
  } catch (e) {
    res.status(401).json({ error: 'Unauthorized' });
  }
});
